# -*- coding: utf-8 -*-
"""Prodigy_GA_task3.0

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YtimAxReHcM-2I63m0D0YKNqrlzf0BYe
"""

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1CMiAMPMiZLOfwIikoTgVvqOvcXpMp_M2",
      "authorship_tag": "ABX9TyP1S8kLAEqRt0QaiQIi/pxU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gauravv-x/Prodigy-Internship/blob/main/PRODIGY_GA_03.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing** **tools**"
      ],
      "metadata": {
        "id": "n5w49MUC3yAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YMhsy2WU9YFp",
        "outputId": "a4250d36-c841-4626-e641-3177b242a501"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import random"
      ],
      "metadata": {
        "id": "1wWRF7n413kR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading every Sherlock Holmes adventure!"
      ],
      "metadata": {
        "id": "A8ogFXJq31eI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2-HpE0sy8mqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "story_path = \"/content/drive/MyDrive/sherlock/sherlock/\"\n",
        "\n",
        "def read_all_stories(story_path):\n",
        "    txt = []\n",
        "    for _, _, files in os.walk(story_path):\n",
        "        for file in files:\n",
        "            with open(story_path+file) as f:\n",
        "                for line in f:\n",
        "                    line = line.strip()\n",
        "                    if line=='----------': break\n",
        "                    if line!='':txt.append(line)\n",
        "    return txt\n",
        "\n",
        "stories = read_all_stories(story_path)\n",
        "print(\"number of lines = \", len(stories))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0riUIEq3f7n",
        "outputId": "b92f4cda-17e2-4b0e-b8a9-dcf911221db0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of lines =  215021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning the text"
      ],
      "metadata": {
        "id": "jqgmAj4H337Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_txt(txt):\n",
        "    cleaned_txt = []\n",
        "    for line in txt:\n",
        "        line = line.lower()\n",
        "        line = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\]\", \"\", line)\n",
        "        tokens = word_tokenize(line)\n",
        "        words = [word for word in tokens if word.isalpha()]\n",
        "        cleaned_txt+=words\n",
        "    return cleaned_txt\n",
        "\n",
        "cleaned_stories = clean_txt(stories)\n",
        "print(\"number of words = \", len(cleaned_stories))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4XDj-8h89lD",
        "outputId": "d4a12690-e286-46bd-db8a-ed490d4963d4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of words =  2332247\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the Markov Model"
      ],
      "metadata": {
        "id": "hCKCMqd23-Y3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_markov_model(cleaned_stories, n_gram=2):\n",
        "    markov_model = {}\n",
        "    for i in range(len(cleaned_stories)-n_gram-1):\n",
        "        curr_state, next_state = \"\", \"\"\n",
        "        for j in range(n_gram):\n",
        "            curr_state += cleaned_stories[i+j] + \" \"\n",
        "            next_state += cleaned_stories[i+j+n_gram] + \" \"\n",
        "        curr_state = curr_state[:-1]\n",
        "        next_state = next_state[:-1]\n",
        "        if curr_state not in markov_model:\n",
        "            markov_model[curr_state] = {}\n",
        "            markov_model[curr_state][next_state] = 1\n",
        "        else:\n",
        "            if next_state in markov_model[curr_state]:\n",
        "                markov_model[curr_state][next_state] += 1\n",
        "            else:\n",
        "                markov_model[curr_state][next_state] = 1\n",
        "\n",
        "    # calculating transition probabilities\n",
        "    for curr_state, transition in markov_model.items():\n",
        "        total = sum(transition.values())\n",
        "        for state, count in transition.items():\n",
        "            markov_model[curr_state][state] = count/total\n",
        "\n",
        "    return markov_model"
      ],
      "metadata": {
        "id": "n1_7Al734Anh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "markov_model = make_markov_model(cleaned_stories)"
      ],
      "metadata": {
        "id": "cJleq82r4Kyb"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"number of states = \", len(markov_model.keys()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Oxj5_Zm4My7",
        "outputId": "77b7b1de-4965-4151-fba0-0efddcd9635d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of states =  208714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"All possible transitions from 'the game' state: \\n\")\n",
        "print(markov_model['the game'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFyMpjSy4Qmr",
        "outputId": "1c792928-73f7-41f9-e652-b5e564c26b2e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All possible transitions from 'the game' state: \n",
            "\n",
            "{'is afoot': 0.036036036036036036, 'your letter': 0.02702702702702703, 'was up': 0.09009009009009009, 'for the': 0.036036036036036036, 'was in': 0.02702702702702703, 'is hardly': 0.02702702702702703, 'would have': 0.036036036036036036, 'is up': 0.06306306306306306, 'is and': 0.036036036036036036, 'in their': 0.036036036036036036, 'was whist': 0.036036036036036036, 'in that': 0.036036036036036036, 'the lack': 0.036036036036036036, 'for all': 0.06306306306306306, 'may wander': 0.02702702702702703, 'now a': 0.02702702702702703, 'my own': 0.02702702702702703, 'at any': 0.02702702702702703, 'mr holmes': 0.02702702702702703, 'ay whats': 0.02702702702702703, 'my friend': 0.02702702702702703, 'fairly by': 0.02702702702702703, 'is not': 0.02702702702702703, 'was not': 0.02702702702702703, 'was afoot': 0.036036036036036036, 'worth it': 0.02702702702702703, 'you are': 0.02702702702702703, 'i am': 0.02702702702702703, 'now count': 0.02702702702702703}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating Sherlock Holmes stories!"
      ],
      "metadata": {
        "id": "8j9N5t1S9uLp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_story(markov_model, limit=100, start='my god'):\n",
        "    n = 0\n",
        "    curr_state = start\n",
        "    next_state = None\n",
        "    story = \"\"\n",
        "    story+=curr_state+\" \"\n",
        "    while n<limit:\n",
        "        next_state = random.choices(list(markov_model[curr_state].keys()),\n",
        "                                    list(markov_model[curr_state].values()))\n",
        "\n",
        "        curr_state = next_state[0]\n",
        "        story+=curr_state+\" \"\n",
        "        n+=1\n",
        "    return story"
      ],
      "metadata": {
        "id": "h1aRd6W_9u3q"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    print(str(i)+\". \", generate_story(markov_model, start=\"dear holmes\", limit=8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gcJVRxI9zCs",
        "outputId": "9ab51b35-b1d8-4dd9-d328-d9584b4fa5d2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.  dear holmes i fear that it contains a full explanation of the principal streets and other signs of \n",
            "1.  dear holmes i exclaimed how on earth you got yourself mixed up in this hotel and waited there \n",
            "2.  dear holmes oh yes it is unlikely that it is a long vigil well asked von bork eagerly \n",
            "3.  dear holmes am i charged with it there you perhaps i have found a way out to the \n",
            "4.  dear holmes what do you make of it there will no longer he paced up and down talking \n",
            "5.  dear holmes said i quite so said he perhaps you would be needed to make so young a \n",
            "6.  dear holmes you are sure of it who profits by it there are two possible explanations and only \n",
            "7.  dear holmes i fear that i was ready to devote his life of which they were all three \n",
            "8.  dear holmes what do you intend to do with the immense stream of commerce flowing in a double \n",
            "9.  dear holmes oh yes no doubt there only remains mrs toller who might give him time to perpetrate \n",
            "10.  dear holmes that i have heard of none there was no doubt that the description of them they \n",
            "11.  dear holmes he has been very kind said dr mortimer for introducing me to the discomforts of my \n",
            "12.  dear holmes said i you may safely trust him for his unmanly conduct but you shall judge for \n",
            "13.  dear holmes am i then you will see it often in humans i have just left him and \n",
            "14.  dear holmes am i to do that but what are you loitering there for the book is one \n",
            "15.  dear holmes i exclaimed and then composed himself with his colour made me think he was against employing \n",
            "16.  dear holmes said i can follow the other i followed holmes up the small but instructive adventure which \n",
            "17.  dear holmes what do you make another slip well it is not paid on a princely scale splendid \n",
            "18.  dear holmes you are the very thought it was caused by the sleeve where do you propose now \n",
            "19.  dear holmes he has done no doubt that she knew that the bird was indeed flown it is \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    print(str(i)+\". \", generate_story(markov_model, start=\"my dear\", limit=8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5idBbruf93_D",
        "outputId": "82c2b248-b8c9-424b-ce57-d95177b1abe6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.  my dear fellow said he in his blandest voice this northern air is invigorating and pleasant one and \n",
            "1.  my dear young lady resumed her seat with an air of deep black hair the large tin of \n",
            "2.  my dear watson said he and he watched us with a face of granite concealed our approach and \n",
            "3.  my dear watson you have one more specimen of the face on him like a madman coming along \n",
            "4.  my dear watson said holmes pulling at his watch and no one would take this opportunity to remark \n",
            "5.  my dear daughter alice and spoke sharply like a man to carry on their reprehensible careers perhaps in \n",
            "6.  my dear fellow you know that photograph no i dont suppose they remember faces in so delicate a \n",
            "7.  my dear watson there is a good deal however i may say so without offence seem superior to \n",
            "8.  my dear watson should realize said barker quickly as he leaned back in the least nor running a \n",
            "9.  my dear watson with the i laid his hand upon the table laid out upon the varnish would \n",
            "10.  my dear mr holmes an exposure what can i tell you it is this lord bellinger twice premier \n",
            "11.  my dear fellow you shall keep you whether we have solved the mystery of the sinister german or \n",
            "12.  my dear holmes that ever i handled and yet at first it may be difficult for me to \n",
            "13.  my dear fellow you see exactly the same state i shall fear that you might treat us with \n",
            "14.  my dear watson you have added to cocaine injections and all the actors in this drama as i \n",
            "15.  my dear watson we shall have to go he never came out of this hat but as there \n",
            "16.  my dear watson but if i could get away i could catch a glimpse of a page no \n",
            "17.  my dear girl it would break any image of him gown and had left it in this gladstone \n",
            "18.  my dear watson you will find no case could be no doubt he is in serious trouble in \n",
            "19.  my dear watson can be trusted i went to my companion neither the country on the inside and \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    print(str(i)+\". \", generate_story(markov_model, start=\"i would\", limit=8))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRE4rT3e95dx",
        "outputId": "1ae6c488-5ace-4296-8e0d-a2946805e074"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.  i would lay a little child with her round white arms encircling his brown face looked so savage \n",
            "1.  i would have nothing to do much soldiering however i found that i was not surprised when holmes \n",
            "2.  i would have spoken the truth now holmes and you have got to the door and closed it \n",
            "3.  i would it seemed to me the count von kramm a bohemian dealer in london who loves her \n",
            "4.  i would go for the men i wanted badly to have a deal to worry and try me \n",
            "5.  i would pay ten that would explain wests conduct or could the first pioneer who had only left \n",
            "6.  i would promise for three months and read it aloud abbey grange to be in a very remarkable \n",
            "7.  i would bring the business to which my sister died of the building where a steep stair led \n",
            "8.  i would ask the lodge to meet her from the window he came down to be to me \n",
            "9.  i would some hours ago when i read with a narrow band of grass between the oak and \n",
            "10.  i would rather never allude to that which was uppermost it is beyond our little clearings was infested \n",
            "11.  i would not leave her lying wounded upon the floor and was starting that very afternoon to rejoin \n",
            "12.  i would do it again deeply as i can speak easy it was for richmond it is the \n",
            "13.  i would not have been discovered the commissionaire plumped down into a short thoroughfare lined with barrels mcginty \n",
            "14.  i would prove it as the most incisive reasoner and most energetic agent in search of his son \n",
            "15.  i would be at your service some years ago this country house of yours will bring us a \n",
            "16.  i would do it then who are you the parties who come with miss morstan he asked i \n",
            "17.  i would spare you five minutes let us end the dim glazed eyes staring from a flint but \n",
            "18.  i would handle it right they can never be yours what ails you it is really the most \n",
            "19.  i would dog them and follow two tracks instead of the darkest corner of the square white facing \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_story(markov_model, start=\"the case\", limit=100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9UedYoC9_Ej",
        "outputId": "99fe49da-f185-44de-b230-a8cd05c54093"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the case of the tropics a series of flaming headlines which began with the account of the past all was for my line whether its passing or tackling or dribbling theres no more to london it is there a telegram will come up colonel i will make more plain when we meet then how cadogan west met his end at the very volume to which these figures refer holmess calculation was fulfilled a fortnight a week of the ming dynasty no finer piece ever passed through after me like a tiger himself i wonder that you saw this morning but it is not long after my afghan experiences i saw nothing of this affair it is only an hour ago has not been seen talking earnestly to madame on the same floor as the door closed once more i remember right who was said lestrade you said it was mr staunton when he received us in sussex the inspector was annoyed you he relit the stair the criminals i had thought by the way mortimer said that the adequate cataloguing of one of the clergyman he sat with his mouth horribly open i shall be happy until you know that that mark \n"
          ]
        }
      ]
    }
  ]
}